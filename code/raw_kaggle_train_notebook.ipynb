{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":94844,"databundleVersionId":11268212,"sourceType":"competition"},{"sourceId":237396934,"sourceType":"kernelVersion"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":2342.229456,"end_time":"2025-04-29T20:04:32.106268","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-04-29T19:25:29.876812","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0036bdebff704e448e0705fd6baa238f":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04828507c9124e6aba7bd79309245a05":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0425a5a7bae4ba9bd68029770ed7b6c","IPY_MODEL_90448d26cedd4fe185e8b05f477b193f","IPY_MODEL_ca9ca8d37c574859bd2a74d1c0712017"],"layout":"IPY_MODEL_0855b83746da4185998a4ffca4f24bc6","tabbable":null,"tooltip":null}},"06fdebc1adc7452ba5e3ada03b6c623a":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_fdde13b26ea949c2b8607988604c1bbd","placeholder":"​","style":"IPY_MODEL_9ee78cde41d84b7ab91ef1348e0e44b5","tabbable":null,"tooltip":null,"value":" 899k/899k [00:00&lt;00:00, 22.8MB/s]"}},"0855b83746da4185998a4ffca4f24bc6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a50f04c151b46f3bbc1d2632773c1ba":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_51750454b8574383af5e4f31122ddaac","placeholder":"​","style":"IPY_MODEL_a0dead9c173744f68236f47d005286e6","tabbable":null,"tooltip":null,"value":" 456k/456k [00:00&lt;00:00, 47.1MB/s]"}},"0c2d3201e822484b9f52ec5ed33789b2":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c8d09145fb64bc0b4a111ba95161b8b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"14ed3ac33356433e927447ee6a23014b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c8ba4bb2f164aa8b2dacf2e070baca8","IPY_MODEL_1b949836340a4698b947a3e6446b80d1","IPY_MODEL_0a50f04c151b46f3bbc1d2632773c1ba"],"layout":"IPY_MODEL_69193333a18f4c01a7234f603578ac85","tabbable":null,"tooltip":null}},"18f2b13c86ea40c8a8c1866e8af04ec0":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b949836340a4698b947a3e6446b80d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_a470f8c106824d828cd40b6c448db586","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6bffe03e811f43d9b5b0a5c9267af5d1","tabbable":null,"tooltip":null,"value":456318}},"22603d0f55a247938cff129891114247":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"26b2945b2948478981eb4a7ad037b18d":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dc1f26d0b09494abc5641c1b52baafa":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e70dca7815b4470924a57e359ce5f4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_2dc1f26d0b09494abc5641c1b52baafa","placeholder":"​","style":"IPY_MODEL_fa0e5b811fe9413388283abbe43025b3","tabbable":null,"tooltip":null,"value":"vocab.json: 100%"}},"338a4a262dc6461997f3df9bba8ec063":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43ef34be376e4fd9ab6c1990607d1d22":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47fa5bb1637442e8a6728b0706c4da77":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"500b7314f5944cdbb46e70c75d5d36e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_43ef34be376e4fd9ab6c1990607d1d22","placeholder":"​","style":"IPY_MODEL_8695def4d2c94eaf9cbc75f7a5437278","tabbable":null,"tooltip":null,"value":" 474/474 [00:00&lt;00:00, 64.6kB/s]"}},"51750454b8574383af5e4f31122ddaac":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"559cea138a714350a4bc5d44e8180958":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e70dca7815b4470924a57e359ce5f4f","IPY_MODEL_fb30667b0a2543caa657d3d6deebeb00","IPY_MODEL_06fdebc1adc7452ba5e3ada03b6c623a"],"layout":"IPY_MODEL_aef28de5ef514ccf9115cdec96b6fcc6","tabbable":null,"tooltip":null}},"5c8ba4bb2f164aa8b2dacf2e070baca8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_f4877daf64754a139b32744c15228122","placeholder":"​","style":"IPY_MODEL_c824f67792a94c9c96c4cb87fbcc9352","tabbable":null,"tooltip":null,"value":"merges.txt: 100%"}},"6702607cc87148c29222b828fb63e3a1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_c4d5398a22414da099e1e479b75716a5","placeholder":"​","style":"IPY_MODEL_ec0763f89a524944839e8bf51c4d0fbe","tabbable":null,"tooltip":null,"value":"config.json: 100%"}},"69193333a18f4c01a7234f603578ac85":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bffe03e811f43d9b5b0a5c9267af5d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d158ee2ad07479f85586383c313e3c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"70a88bb8d3594597945b89b4c7e5fcab":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"723af29505e54bbd9b404e123ed9c769":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_92eb60a4c6434c9b89c6329183b19c5d","IPY_MODEL_d4002616795d4c48b7c33ef1dd15b017","IPY_MODEL_e26641af9b774e05ae7980e8abe2c78e"],"layout":"IPY_MODEL_70a88bb8d3594597945b89b4c7e5fcab","tabbable":null,"tooltip":null}},"7bbdf57197fc491eb44e2bafcae7ac6b":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80dcd15f53c54d1c9ed2ab81342193b3":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84fb3904be614ceaabe2918bfa66c185":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8695def4d2c94eaf9cbc75f7a5437278":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"8f39fdb75f424ae394e5c882345289ab":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90448d26cedd4fe185e8b05f477b193f":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_a99a0d2e07cf46cbb1ee2e75fba87903","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b4b509215e3d4f6f8d424e14eecc8d4b","tabbable":null,"tooltip":null,"value":52}},"92eb60a4c6434c9b89c6329183b19c5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_18f2b13c86ea40c8a8c1866e8af04ec0","placeholder":"​","style":"IPY_MODEL_a78964c65096464897eaf0d86b4d42ca","tabbable":null,"tooltip":null,"value":"model.safetensors: 100%"}},"97d3155e45ee4908b11a0ef50bccf2b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9a7516bfa26a46d7b2d1353fa89045e2","IPY_MODEL_e32f41c773b64df997eacc13e6e58eff","IPY_MODEL_f173f2a6cccc49518a55562bcc30f43b"],"layout":"IPY_MODEL_84fb3904be614ceaabe2918bfa66c185","tabbable":null,"tooltip":null}},"9902b135a5684261bcfe899e16445591":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6702607cc87148c29222b828fb63e3a1","IPY_MODEL_d624e4c468364092ae25c2f4390b0a34","IPY_MODEL_500b7314f5944cdbb46e70c75d5d36e8"],"layout":"IPY_MODEL_8f39fdb75f424ae394e5c882345289ab","tabbable":null,"tooltip":null}},"9a7516bfa26a46d7b2d1353fa89045e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_b30606ae7c124b54baf785d44298fb64","placeholder":"​","style":"IPY_MODEL_be449bdf83404a489a75a5f0094aa9b8","tabbable":null,"tooltip":null,"value":"pytorch_model.bin: 100%"}},"9dc8506d2aa6499a9bc161916a28d661":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ee78cde41d84b7ab91ef1348e0e44b5":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a0dead9c173744f68236f47d005286e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a470f8c106824d828cd40b6c448db586":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a78964c65096464897eaf0d86b4d42ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"a99a0d2e07cf46cbb1ee2e75fba87903":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aef28de5ef514ccf9115cdec96b6fcc6":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b30606ae7c124b54baf785d44298fb64":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4b509215e3d4f6f8d424e14eecc8d4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be449bdf83404a489a75a5f0094aa9b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"be93d73314ee4c4ab1c6f212de6114c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0425a5a7bae4ba9bd68029770ed7b6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_dee4a1745232421a8050ce988339dd9c","placeholder":"​","style":"IPY_MODEL_fab188f93fa34cc690a089fa1abaff83","tabbable":null,"tooltip":null,"value":"tokenizer_config.json: 100%"}},"c4d5398a22414da099e1e479b75716a5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c824f67792a94c9c96c4cb87fbcc9352":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"ca9ca8d37c574859bd2a74d1c0712017":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_80dcd15f53c54d1c9ed2ab81342193b3","placeholder":"​","style":"IPY_MODEL_f2b457eb8c6b4175a4894555eb878335","tabbable":null,"tooltip":null,"value":" 52.0/52.0 [00:00&lt;00:00, 5.69kB/s]"}},"d4002616795d4c48b7c33ef1dd15b017":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_0c2d3201e822484b9f52ec5ed33789b2","max":558573788,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be93d73314ee4c4ab1c6f212de6114c6","tabbable":null,"tooltip":null,"value":558573788}},"d624e4c468364092ae25c2f4390b0a34":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_0036bdebff704e448e0705fd6baa238f","max":474,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9dc8506d2aa6499a9bc161916a28d661","tabbable":null,"tooltip":null,"value":474}},"dee4a1745232421a8050ce988339dd9c":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e26641af9b774e05ae7980e8abe2c78e":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_7bbdf57197fc491eb44e2bafcae7ac6b","placeholder":"​","style":"IPY_MODEL_0c8d09145fb64bc0b4a111ba95161b8b","tabbable":null,"tooltip":null,"value":" 559M/559M [00:02&lt;00:00, 209MB/s]"}},"e32f41c773b64df997eacc13e6e58eff":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_eb9e6fd3873a4eef9f0627fc86e0edd5","max":558614189,"min":0,"orientation":"horizontal","style":"IPY_MODEL_22603d0f55a247938cff129891114247","tabbable":null,"tooltip":null,"value":558614189}},"eb9e6fd3873a4eef9f0627fc86e0edd5":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec0763f89a524944839e8bf51c4d0fbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f173f2a6cccc49518a55562bcc30f43b":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"HTMLView","description":"","description_allow_html":false,"layout":"IPY_MODEL_338a4a262dc6461997f3df9bba8ec063","placeholder":"​","style":"IPY_MODEL_47fa5bb1637442e8a6728b0706c4da77","tabbable":null,"tooltip":null,"value":" 559M/559M [00:02&lt;00:00, 288MB/s]"}},"f2b457eb8c6b4175a4894555eb878335":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"f4877daf64754a139b32744c15228122":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa0e5b811fe9413388283abbe43025b3":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"fab188f93fa34cc690a089fa1abaff83":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"HTMLStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"HTMLStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"StyleView","background":null,"description_width":"","font_size":null,"text_color":null}},"fb30667b0a2543caa657d3d6deebeb00":{"model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"2.0.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"2.0.0","_view_name":"ProgressView","bar_style":"success","description":"","description_allow_html":false,"layout":"IPY_MODEL_26b2945b2948478981eb4a7ad037b18d","max":898825,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6d158ee2ad07479f85586383c313e3c7","tabbable":null,"tooltip":null,"value":898825}},"fdde13b26ea949c2b8607988604c1bbd":{"model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"2.0.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"2.0.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border_bottom":null,"border_left":null,"border_right":null,"border_top":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-05-02T15:12:45.611854Z","iopub.execute_input":"2025-05-02T15:12:45.612014Z","iopub.status.idle":"2025-05-02T15:12:47.591254Z","shell.execute_reply.started":"2025-05-02T15:12:45.611999Z","shell.execute_reply":"2025-05-02T15:12:47.590682Z"},"papermill":{"duration":1.63068,"end_time":"2025-04-29T19:25:35.692810","exception":false,"start_time":"2025-04-29T19:25:34.062130","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/comp-4211-spring-25-project/sample_submission.csv\n/kaggle/input/comp-4211-spring-25-project/train.csv\n/kaggle/input/comp-4211-spring-25-project/test.csv\n/kaggle/input/derberta/__results__.html\n/kaggle/input/derberta/v7_submission.zip\n/kaggle/input/derberta/v7_submission.csv\n/kaggle/input/derberta/__huggingface_repos__.json\n/kaggle/input/derberta/__notebook__.ipynb\n/kaggle/input/derberta/__output__.json\n/kaggle/input/derberta/augmented_train.csv\n/kaggle/input/derberta/custom.css\n/kaggle/input/derberta/v7_results/checkpoint-1004/config.json\n/kaggle/input/derberta/v7_results/checkpoint-1004/trainer_state.json\n/kaggle/input/derberta/v7_results/checkpoint-1004/training_args.bin\n/kaggle/input/derberta/v7_results/checkpoint-1004/scheduler.pt\n/kaggle/input/derberta/v7_results/checkpoint-1004/model.safetensors\n/kaggle/input/derberta/v7_results/checkpoint-1004/optimizer.pt\n/kaggle/input/derberta/v7_results/checkpoint-1004/rng_state.pth\n/kaggle/input/derberta/v7_results/checkpoint-9036/config.json\n/kaggle/input/derberta/v7_results/checkpoint-9036/trainer_state.json\n/kaggle/input/derberta/v7_results/checkpoint-9036/training_args.bin\n/kaggle/input/derberta/v7_results/checkpoint-9036/scheduler.pt\n/kaggle/input/derberta/v7_results/checkpoint-9036/model.safetensors\n/kaggle/input/derberta/v7_results/checkpoint-9036/optimizer.pt\n/kaggle/input/derberta/v7_results/checkpoint-9036/rng_state.pth\n/kaggle/input/derberta/v7_results/checkpoint-2008/config.json\n/kaggle/input/derberta/v7_results/checkpoint-2008/trainer_state.json\n/kaggle/input/derberta/v7_results/checkpoint-2008/training_args.bin\n/kaggle/input/derberta/v7_results/checkpoint-2008/scheduler.pt\n/kaggle/input/derberta/v7_results/checkpoint-2008/model.safetensors\n/kaggle/input/derberta/v7_results/checkpoint-2008/optimizer.pt\n/kaggle/input/derberta/v7_results/checkpoint-2008/rng_state.pth\n/kaggle/input/derberta/v7_results/checkpoint-3012/config.json\n/kaggle/input/derberta/v7_results/checkpoint-3012/trainer_state.json\n/kaggle/input/derberta/v7_results/checkpoint-3012/training_args.bin\n/kaggle/input/derberta/v7_results/checkpoint-3012/scheduler.pt\n/kaggle/input/derberta/v7_results/checkpoint-3012/model.safetensors\n/kaggle/input/derberta/v7_results/checkpoint-3012/optimizer.pt\n/kaggle/input/derberta/v7_results/checkpoint-3012/rng_state.pth\n/kaggle/input/derberta/v7_results/checkpoint-5020/config.json\n/kaggle/input/derberta/v7_results/checkpoint-5020/trainer_state.json\n/kaggle/input/derberta/v7_results/checkpoint-5020/training_args.bin\n/kaggle/input/derberta/v7_results/checkpoint-5020/scheduler.pt\n/kaggle/input/derberta/v7_results/checkpoint-5020/model.safetensors\n/kaggle/input/derberta/v7_results/checkpoint-5020/optimizer.pt\n/kaggle/input/derberta/v7_results/checkpoint-5020/rng_state.pth\n/kaggle/input/derberta/v7_results/checkpoint-6024/config.json\n/kaggle/input/derberta/v7_results/checkpoint-6024/trainer_state.json\n/kaggle/input/derberta/v7_results/checkpoint-6024/training_args.bin\n/kaggle/input/derberta/v7_results/checkpoint-6024/scheduler.pt\n/kaggle/input/derberta/v7_results/checkpoint-6024/model.safetensors\n/kaggle/input/derberta/v7_results/checkpoint-6024/optimizer.pt\n/kaggle/input/derberta/v7_results/checkpoint-6024/rng_state.pth\n/kaggle/input/derberta/v7_results/checkpoint-7028/config.json\n/kaggle/input/derberta/v7_results/checkpoint-7028/trainer_state.json\n/kaggle/input/derberta/v7_results/checkpoint-7028/training_args.bin\n/kaggle/input/derberta/v7_results/checkpoint-7028/scheduler.pt\n/kaggle/input/derberta/v7_results/checkpoint-7028/model.safetensors\n/kaggle/input/derberta/v7_results/checkpoint-7028/optimizer.pt\n/kaggle/input/derberta/v7_results/checkpoint-7028/rng_state.pth\n/kaggle/input/derberta/v7_results/checkpoint-8032/config.json\n/kaggle/input/derberta/v7_results/checkpoint-8032/trainer_state.json\n/kaggle/input/derberta/v7_results/checkpoint-8032/training_args.bin\n/kaggle/input/derberta/v7_results/checkpoint-8032/scheduler.pt\n/kaggle/input/derberta/v7_results/checkpoint-8032/model.safetensors\n/kaggle/input/derberta/v7_results/checkpoint-8032/optimizer.pt\n/kaggle/input/derberta/v7_results/checkpoint-8032/rng_state.pth\n/kaggle/input/derberta/v7_results/checkpoint-10030/config.json\n/kaggle/input/derberta/v7_results/checkpoint-10030/trainer_state.json\n/kaggle/input/derberta/v7_results/checkpoint-10030/training_args.bin\n/kaggle/input/derberta/v7_results/checkpoint-10030/scheduler.pt\n/kaggle/input/derberta/v7_results/checkpoint-10030/model.safetensors\n/kaggle/input/derberta/v7_results/checkpoint-10030/optimizer.pt\n/kaggle/input/derberta/v7_results/checkpoint-10030/rng_state.pth\n/kaggle/input/derberta/v7_results/checkpoint-4016/config.json\n/kaggle/input/derberta/v7_results/checkpoint-4016/trainer_state.json\n/kaggle/input/derberta/v7_results/checkpoint-4016/training_args.bin\n/kaggle/input/derberta/v7_results/checkpoint-4016/scheduler.pt\n/kaggle/input/derberta/v7_results/checkpoint-4016/model.safetensors\n/kaggle/input/derberta/v7_results/checkpoint-4016/optimizer.pt\n/kaggle/input/derberta/v7_results/checkpoint-4016/rng_state.pth\n/kaggle/input/derberta/nltk_data/corpora/wordnet.zip\n/kaggle/input/derberta/nltk_data/tokenizers/punkt.zip\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/portuguese.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/greek.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/estonian.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/czech.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/danish.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/russian.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/README\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/english.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/italian.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/german.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/polish.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/french.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/norwegian.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/swedish.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/dutch.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/slovene.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/.DS_Store\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/malayalam.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/turkish.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/spanish.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/finnish.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/portuguese.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/greek.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/estonian.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/czech.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/danish.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/russian.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/README\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/english.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/italian.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/german.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/polish.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/french.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/norwegian.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/swedish.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/dutch.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/slovene.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/malayalam.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/turkish.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/spanish.pickle\n/kaggle/input/derberta/nltk_data/tokenizers/punkt/PY3/finnish.pickle\n/kaggle/input/derberta/nltk_data/taggers/averaged_perceptron_tagger_eng.zip\n/kaggle/input/derberta/nltk_data/taggers/averaged_perceptron_tagger_eng/averaged_perceptron_tagger_eng.tagdict.json\n/kaggle/input/derberta/nltk_data/taggers/averaged_perceptron_tagger_eng/averaged_perceptron_tagger_eng.weights.json\n/kaggle/input/derberta/nltk_data/taggers/averaged_perceptron_tagger_eng/averaged_perceptron_tagger_eng.classes.json\n/kaggle/input/derberta/v7_model/config.json\n/kaggle/input/derberta/v7_model/merges.txt\n/kaggle/input/derberta/v7_model/training_args.bin\n/kaggle/input/derberta/v7_model/tokenizer.json\n/kaggle/input/derberta/v7_model/vocab.json\n/kaggle/input/derberta/v7_model/tokenizer_config.json\n/kaggle/input/derberta/v7_model/model.safetensors\n/kaggle/input/derberta/v7_model/special_tokens_map.json\n/kaggle/input/derberta/v7_submission/infer.py\n/kaggle/input/derberta/v7_submission/submission.csv\n/kaggle/input/derberta/v7_submission/requirements.txt\n/kaggle/input/derberta/v7_submission/run.sh\n/kaggle/input/derberta/v7_submission/model/config.json\n/kaggle/input/derberta/v7_submission/model/merges.txt\n/kaggle/input/derberta/v7_submission/model/tokenizer.json\n/kaggle/input/derberta/v7_submission/model/vocab.json\n/kaggle/input/derberta/v7_submission/model/tokenizer_config.json\n/kaggle/input/derberta/v7_logs/events.out.tfevents.1746190220.ad640fd56bfe.19.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Cell 2: Install hf_xet and libraries\ntry:\n    import hf_xet\n    print(\"hf_xet found, using Xet Storage for faster downloads.\")\nexcept ImportError:\n    print(\"Installing hf_xet for faster Hugging Face downloads...\")\n    !pip install hf_xet\n    try:\n        import hf_xet\n        print(\"hf_xet installed successfully.\")\n    except ImportError:\n        print(\"Failed to install hf_xet. Continuing with standard HTTP download.\")\n\ntry:\n    import torch\n    print(f\"torch version: {torch.__version__}\")\nexcept ImportError:\n    !pip install torch==2.5.1+cu124\n    import torch\n    print(f\"torch version: {torch.__version__}\")\n\ntry:\n    from torchcrf import CRF\n    print(\"torchcrf imported successfully.\")\nexcept ImportError:\n    print(\"Installing pytorch-crf...\")\n    os.system(\"pip install pytorch-crf==0.7.2\")\n    from torchcrf import CRF\n    print(\"torchcrf installed and imported.\")\n\ntry:\n    import nlpaug\n    print(f\"nlpaug version: {nlpaug.__version__}\")\nexcept ImportError:\n    !pip install nlpaug==1.1.11\n    import nlpaug\n    print(f\"nlpaug version: {nlpaug.__version__}\")\n\ntry:\n    import transformers\n    print(f\"transformers version: {transformers.__version__}\")\nexcept ImportError:\n    !pip install transformers==4.51.1\n    import transformers\n    print(f\"transformers version: {transformers.__version__}\")\n\ntry:\n    import sklearn\n    print(f\"scikit-learn version: {sklearn.__version__}\")\nexcept ImportError:\n    !pip install scikit-learn==1.2.2\n    import sklearn\n    print(f\"scikit-learn version: {sklearn.__version__}\")\n\ntry:\n    import nltk\n    print(\"nltk found\")\nexcept ImportError:\n    !pip install nltk\n    import nltk\n    print(\"nltk installed and imported.\")\n\n# Additional imports\nimport os\nos.environ['WANDB_MODE'] = 'disabled'  # Disable Weights & Biases logging\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nimport ast\nimport shutil\nfrom collections import Counter\nfrom transformers.trainer_utils import set_seed\nimport nlpaug.augmenter.word as naw\n\n# Custom DebertaCRF model\nclass DebertaCRF(AutoModelForTokenClassification):\n    def __init__(self, config):\n        super().__init__(config)\n        self.crf = CRF(num_tags=config.num_labels, batch_first=True)\n\n    def forward(self, input_ids, attention_mask=None, labels=None):\n        outputs = super().forward(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        if labels is not None:\n            mask = attention_mask.bool()\n            loss = -self.crf(logits, labels, mask=mask, reduction='mean')\n            return {'loss': loss}\n        else:\n            predictions = self.crf.decode(logits, mask=attention_mask.bool())\n            return {'predictions': predictions}\n\n# Set random seed for reproducibility\nset_seed(42)\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n# Download NLTK data\ntry:\n    nltk_data_dir = '/kaggle/working/nltk_data'\n    if not os.path.exists(nltk_data_dir):\n        os.makedirs(nltk_data_dir)\n    nltk.data.path.append(nltk_data_dir)\n    print(\"Downloading NLTK data...\")\n    nltk.download('punkt', download_dir=nltk_data_dir, quiet=True)\n    nltk.download('averaged_perceptron_tagger_eng', download_dir=nltk_data_dir, quiet=True)\n    nltk.download('wordnet', download_dir=nltk_data_dir, quiet=True)\n    nltk.data.find('taggers/averaged_perceptron_tagger_eng')\n    print(\"NLTK data downloaded and verified.\")\nexcept Exception as e:\n    print(f\"Error downloading NLTK data: {e}\")\n    raise SystemExit(\"Failed to download NLTK data.\")","metadata":{"execution":{"iopub.status.busy":"2025-05-02T15:02:16.373741Z","iopub.execute_input":"2025-05-02T15:02:16.374217Z","iopub.status.idle":"2025-05-02T15:04:05.729248Z","shell.execute_reply.started":"2025-05-02T15:02:16.374190Z","shell.execute_reply":"2025-05-02T15:04:05.728135Z"},"papermill":{"duration":68.456252,"end_time":"2025-04-29T19:26:44.151791","exception":false,"start_time":"2025-04-29T19:25:35.695539","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Installing hf_xet for faster Hugging Face downloads...\nCollecting hf_xet\n  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\nDownloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: hf_xet\nSuccessfully installed hf_xet-1.1.0\nhf_xet installed successfully.\ntorch version: 2.5.1+cu124\nInstalling pytorch-crf...\nCollecting pytorch-crf==0.7.2\n  Downloading pytorch_crf-0.7.2-py3-none-any.whl.metadata (2.4 kB)\nDownloading pytorch_crf-0.7.2-py3-none-any.whl (9.5 kB)\nInstalling collected packages: pytorch-crf\nSuccessfully installed pytorch-crf-0.7.2\ntorchcrf installed and imported.\nCollecting nlpaug==1.1.11\n  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from nlpaug==1.1.11) (1.26.4)\nRequirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug==1.1.11) (2.2.3)\nRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug==1.1.11) (2.32.3)\nRequirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug==1.1.11) (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug==1.1.11) (4.13.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug==1.1.11) (3.18.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug==1.1.11) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug==1.1.11) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug==1.1.11) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug==1.1.11) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug==1.1.11) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug==1.1.11) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.16.2->nlpaug==1.1.11) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug==1.1.11) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug==1.1.11) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2.0->nlpaug==1.1.11) (2025.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->nlpaug==1.1.11) (2025.1.31)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug==1.1.11) (1.17.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug==1.1.11) (2.6)\nRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug==1.1.11) (4.13.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.2->nlpaug==1.1.11) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.16.2->nlpaug==1.1.11) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.16.2->nlpaug==1.1.11) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.16.2->nlpaug==1.1.11) (2024.2.0)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug==1.1.11) (1.7.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.16.2->nlpaug==1.1.11) (2024.2.0)\nDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nlpaug\nSuccessfully installed nlpaug-1.1.11\nnlpaug version: 1.1.11\ntransformers version: 4.51.1\nscikit-learn version: 1.2.2\nnltk found\n","output_type":"stream"},{"name":"stderr","text":"2025-05-02 15:02:51.525324: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746198171.799350      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746198171.882339      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Downloading NLTK data...\nNLTK data downloaded and verified.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Cell 3: Load training data\ndef find_train_csv(input_dir='/kaggle/input'):\n    try:\n        for root, _, files in os.walk(input_dir):\n            if 'train.csv' in files:\n                return os.path.join(root, 'train.csv')\n        return None\n    except Exception as e:\n        print(f\"Error searching for train.csv: {e}\")\n        return None\n\ntrain_path = find_train_csv()\ntest_path = '/kaggle/input/comp-4211 spring-25-project/test.csv'\n\nif not train_path or not os.path.exists(train_path):\n    print(f\"Error: train.csv not found in /kaggle/input\")\n    print(\"Please ensure the 'comp-4211 spring-25-project' dataset is attached in Kaggle's Data tab.\")\n    raise SystemExit(\"Failed to locate train.csv.\")\n\ntry:\n    print(f\"Loading train.csv from {train_path}\")\n    train_df = pd.read_csv(train_path)\n    train_df['Sentence'] = train_df['Sentence'].apply(ast.literal_eval)\n    train_df['NER Tag'] = train_df['NER Tag'].apply(ast.literal_eval)\n    print(f\"Training data loaded successfully. Shape: {train_df.shape}\")\nexcept FileNotFoundError:\n    print(f\"Error: Training file not found at {train_path}\")\n    raise SystemExit(\"Ensure train.csv exists in the specified path.\")\nexcept Exception as e:\n    print(f\"Error loading training data: {e}\")\n    raise SystemExit(\"Failed to load or preprocess training data.\")\n\n# Define labels\ntry:\n    unique_labels = set()\n    for tags in train_df['NER Tag']:\n        unique_labels.update(tags)\n    unique_labels_list = sorted(list(unique_labels))\n    label2id = {v: k for k, v in enumerate(unique_labels_list)}\n    id2label = {k: v for k, v in enumerate(unique_labels_list)}\n    print(f\"Unique labels: {unique_labels_list}\")\n    print(f\"Number of labels: {len(unique_labels_list)}\")\nexcept Exception as e:\n    print(f\"Error defining labels: {e}\")\n    raise SystemExit(\"Failed to process NER tags.\")","metadata":{"execution":{"iopub.execute_input":"2025-04-29T19:26:44.160381Z","iopub.status.busy":"2025-04-29T19:26:44.159786Z","iopub.status.idle":"2025-04-29T19:26:47.331294Z","shell.execute_reply":"2025-04-29T19:26:47.330536Z"},"papermill":{"duration":3.176892,"end_time":"2025-04-29T19:26:47.332417","exception":false,"start_time":"2025-04-29T19:26:44.155525","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 4: Data augmentation\ndef augment_data(dataframe, label2id, rare_classes=['B-art', 'B-eve', 'B-nat'], aug_path='/kaggle/working/augmented_train.csv'):\n    try:\n        # Check if augmented data exists\n        if os.path.exists(aug_path):\n            augmented_df = pd.read_csv(aug_path)\n            augmented_df['Sentence'] = augmented_df['Sentence'].apply(ast.literal_eval)\n            augmented_df['NER Tag'] = augmented_df['NER Tag'].apply(ast.literal_eval)\n            print(f\"Loaded existing augmented data from {aug_path}. Shape: {augmented_df.shape}\")\n            return augmented_df\n\n        # Perform augmentation\n        aug = naw.SynonymAug(aug_src='wordnet')\n        augmented_data = []\n        for idx, row in dataframe.iterrows():\n            sentence = row['Sentence']\n            tags = row['NER Tag']\n            if any(tag in rare_classes for tag in tags):\n                aug_sentence = aug.augment(' '.join(sentence))\n                aug_sentence = aug_sentence[0].split()\n                if len(aug_sentence) == len(sentence):\n                    augmented_data.append({'Sentence': aug_sentence, 'NER Tag': tags})\n        augmented_df = pd.DataFrame(augmented_data)\n        augmented_df = pd.concat([dataframe, augmented_df], ignore_index=True)\n        print(f\"Augmented data shape: {augmented_df.shape}\")\n        print(f\"Added {len(augmented_data)} augmented examples.\")\n\n        # Save augmented data\n        augmented_df.to_csv(aug_path, index=False)\n        print(f\"Augmented data saved to {aug_path}\")\n        return augmented_df\n\n    except Exception as e:\n        print(f\"Error during data augmentation: {e}\")\n        raise SystemExit(\"Failed to augment data.\")\n\n# Apply augmentation\ntry:\n    augmented_train_df = augment_data(train_df, label2id)\nexcept Exception as e:\n    print(f\"Error applying augmentation: {e}\")\n    raise SystemExit(\"Failed to apply data augmentation.\")","metadata":{"execution":{"iopub.execute_input":"2025-04-29T19:26:47.340896Z","iopub.status.busy":"2025-04-29T19:26:47.340502Z","iopub.status.idle":"2025-04-29T19:26:53.609720Z","shell.execute_reply":"2025-04-29T19:26:53.608988Z"},"papermill":{"duration":6.274687,"end_time":"2025-04-29T19:26:53.610954","exception":false,"start_time":"2025-04-29T19:26:47.336267","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 5: Split data\ntry:\n    train_data, val_data = train_test_split(augmented_train_df, test_size=0.2, random_state=42)\n    print(f\"Data split: {len(train_data)} train, {len(val_data)} validation\")\nexcept Exception as e:\n    print(f\"Error splitting data: {e}\")\n    raise SystemExit(\"Failed to split data.\")","metadata":{"execution":{"iopub.execute_input":"2025-04-29T19:26:53.620747Z","iopub.status.busy":"2025-04-29T19:26:53.620513Z","iopub.status.idle":"2025-04-29T19:26:53.633690Z","shell.execute_reply":"2025-04-29T19:26:53.633031Z"},"papermill":{"duration":0.018575,"end_time":"2025-04-29T19:26:53.634715","exception":false,"start_time":"2025-04-29T19:26:53.616140","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 6: Dataset preparation and training\n# Define NER Dataset\nclass NERDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, label2id, is_test=False):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.label2id = label2id\n        self.is_test = is_test\n        self.max_length = 128\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        try:\n            sentence = self.data.iloc[idx]['Sentence']\n            encoding = self.tokenizer(\n                sentence,\n                is_split_into_words=True,\n                return_tensors='pt',\n                padding='max_length',\n                truncation=True,\n                max_length=self.max_length,\n                return_special_tokens_mask=True\n            )\n\n            item = {\n                'input_ids': encoding['input_ids'].squeeze(),\n                'attention_mask': encoding['attention_mask'].squeeze(),\n                'word_ids': encoding.word_ids()\n            }\n\n            if not self.is_test:\n                tags = self.data.iloc[idx]['NER Tag']\n                labels = [self.label2id[tag] for tag in tags]\n                aligned_labels = []\n                current_word_id = None\n                for word_id in encoding.word_ids():\n                    if word_id is None:\n                        aligned_labels.append(-100)\n                    elif word_id != current_word_id:\n                        aligned_labels.append(labels[word_id] if word_id < len(labels) else -100)\n                        current_word_id = word_id\n                    else:\n                        aligned_labels.append(-100)\n                item['labels'] = torch.tensor(aligned_labels, dtype=torch.long)\n\n            return item\n        except Exception as e:\n            print(f\"Error processing dataset item {idx}: {e}\")\n            raise\n\n# Initialize model and tokenizer\nMODEL_NAME = \"microsoft/deberta-base\"\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n    model = DebertaCRF.from_pretrained(\n        MODEL_NAME,\n        num_labels=len(unique_labels_list),\n        id2label=id2label,\n        label2id=label2id\n    )\n    print(\"Model and tokenizer initialized successfully.\")\nexcept Exception as e:\n    print(f\"Error initializing model or tokenizer: {e}\")\n    raise SystemExit(\"Failed to load model or tokenizer.\")\n\n# Training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/v7_results\",\n    eval_strategy=\"epoch\",\n    learning_rate=1e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"macro_f1\",\n    logging_dir=\"/kaggle/working/v7_logs\",\n    logging_steps=100,\n    gradient_accumulation_steps=2\n)\n\n# Compute metrics for evaluation\ndef compute_metrics(eval_pred):\n    try:\n        predictions, labels = eval_pred\n        if isinstance(predictions, dict) and 'predictions' in predictions:\n            pred_ids = predictions['predictions']\n        else:\n            pred_ids = np.argmax(predictions, axis=-1)\n\n        pred_labels = []\n        true_labels = []\n        for pred, label in zip(pred_ids, labels):\n            pred_tags = [id2label[p] for p, l in zip(pred, label) if l != -100]\n            true_tags = [id2label[l] for l in label if l != -100]\n            pred_labels.extend(pred_tags)\n            true_labels.extend(true_tags)\n\n        return {\n            \"weighted_f1\": f1_score(true_labels, pred_labels, average=\"weighted\", labels=unique_labels_list),\n            \"macro_f1\": f1_score(true_labels, pred_labels, average=\"macro\", labels=unique_labels_list)\n        }\n    except Exception as e:\n        print(f\"Error computing metrics: {e}\")\n        raise\n\n# Initialize datasets\ntry:\n    train_dataset = NERDataset(train_data, tokenizer, label2id)\n    val_dataset = NERDataset(val_data, tokenizer, label2id)\n    print(\"Training and validation datasets created successfully.\")\nexcept Exception as e:\n    print(f\"Error creating datasets: {e}\")\n    raise SystemExit(\"Failed to create datasets.\")\n\n# Trainer\ntry:\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        compute_metrics=compute_metrics\n    )\n    print(\"Trainer initialized successfully.\")\nexcept Exception as e:\n    print(f\"Error initializing trainer: {e}\")\n    raise SystemExit(\"Failed to initialize trainer.\")\n\n# Train model\ntry:\n    trainer.train()\nexcept Exception as e:\n    print(f\"Error during training: {e}\")\n    raise SystemExit(\"Failed to train model.\")","metadata":{"execution":{"iopub.execute_input":"2025-04-29T19:26:53.643683Z","iopub.status.busy":"2025-04-29T19:26:53.643476Z","iopub.status.idle":"2025-04-29T20:03:56.956004Z","shell.execute_reply":"2025-04-29T20:03:56.955409Z"},"papermill":{"duration":2223.318723,"end_time":"2025-04-29T20:03:56.957335","exception":false,"start_time":"2025-04-29T19:26:53.638612","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cell 7: Save trained model and generate submission\ndef save_trained_model(model_path='/kaggle/working/v7_model', submission_dir='/kaggle/working/v7_submission'):\n    try:\n        primary_model_path = os.path.abspath(model_path)\n        if not os.path.exists(primary_model_path):\n            os.makedirs(primary_model_path)\n        \n        trainer.save_model(primary_model_path)\n        tokenizer.save_pretrained(primary_model_path)\n        print(f\"Model and tokenizer saved to {primary_model_path}\")\n\n        if os.path.exists(submission_dir):\n            shutil.rmtree(submission_dir)\n        os.makedirs(submission_dir)\n        os.makedirs(os.path.join(submission_dir, 'data'))\n        os.makedirs(os.path.join(submission_dir, 'model'))\n\n        for file in ['pytorch_model.bin', 'config.json', 'vocab.json', 'merges.txt', 'tokenizer.json', 'tokenizer_config.json']:\n            src = os.path.join(primary_model_path, file)\n            if os.path.exists(src):\n                shutil.copy(src, os.path.join(submission_dir, 'model', file))\n                print(f\"Copied {file} to submission directory\")\n\n        print(f\"Model and data prepared in {submission_dir}\")\n    except Exception as e:\n        print(f\"Error saving model: {e}\")\n        raise SystemExit(\"Failed to save model.\")\n\ndef generate_submission(model, tokenizer, trainer, label2id, id2label, output_path='/kaggle/working/v7_submission.csv', submission_dir='/kaggle/working/v7_submission'):\n    try:\n        test_path = None\n        input_dir = '/kaggle/input'\n        for root, _, files in os.walk(input_dir):\n            if 'test.csv' in files:\n                test_path = os.path.join(root, 'test.csv')\n                break\n        if not test_path or not os.path.exists(test_path):\n            raise FileNotFoundError(f\"Test file not found in {input_dir}.\")\n\n        test_df = pd.read_csv(test_path)\n        test_df['Sentence'] = test_df['Sentence'].apply(ast.literal_eval)\n\n        test_dataset = NERDataset(test_df, tokenizer, label2id, is_test=True)\n        predictions, _, _ = trainer.predict(test_dataset)\n\n        pred_tags = []\n        for i, pred in enumerate(predictions):\n            sentence = test_df.iloc[i]['Sentence']\n            word_ids = test_dataset[i]['word_ids']\n            pred_ids = pred['predictions'] if isinstance(pred, dict) else np.argmax(pred, axis=-1)\n            tags = []\n            current_word_id = None\n            token_idx = 0\n            for j, word_id in enumerate(word_ids):\n                if word_id is None:\n                    continue\n                if word_id != current_word_id:\n                    if isinstance(pred_ids, list):\n                        if token_idx < len(pred_ids):\n                            tags.append(id2label[pred_ids[token_idx]])\n                            token_idx += 1\n                        else:\n                            tags.append('O')\n                    else:\n                        tags.append(id2label[pred_ids[j]])\n                    current_word_id = word_id\n            if len(tags) < len(sentence):\n                tags.extend(['O'] * (len(sentence) - len(tags)))\n            elif len(tags) > len(sentence):\n                tags = tags[:len(sentence)]\n            pred_tags.append(tags)\n\n        submission_df = pd.DataFrame({\n            'id': test_df['id'],\n            'NER Tag': [str(tags) for tags in pred_tags]\n        })\n        submission_df.to_csv(output_path, index=False)\n        print(f\"Submission file saved to {output_path}\")\n\n        with open(os.path.join(submission_dir, 'requirements.txt'), 'w') as f:\n            f.write('torch==2.5.1+cu124\\n')\n            f.write('transformers==4.51.1\\n')\n            f.write('pandas==2.2.3\\n')\n            f.write('numpy==1.26.4\\n')\n            f.write('scikit-learn==1.2.2\\n')\n            f.write('nlpaug==1.1.11\\n')\n            f.write('pytorch-crf==0.7.2\\n')\n            f.write('nltk\\n')\n\n        infer_code = \"\"\"\\\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer\nfrom torch.utils.data import Dataset\nimport ast\nimport os\nfrom torchcrf import CRF\n\nclass DebertaCRF(AutoModelForTokenClassification):\n    def __init__(self, config):\n        super().__init__(config)\n        self.crf = CRF(num_tags=config.num_labels, batch_first=True)\n\n    def forward(self, input_ids, attention_mask=None, labels=None):\n        outputs = super().forward(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        if labels is not None:\n            mask = attention_mask.bool()\n            loss = -self.crf(logits, labels, mask=mask, reduction='mean')\n            return {'loss': loss}\n        else:\n            predictions = self.crf.decode(logits, mask=attention_mask.bool())\n            return {'predictions': predictions}\n\nclass NERDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, label2id, is_test=False):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.label2id = label2id\n        self.is_test = is_test\n        self.max_length = 128\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        sentence = self.data.iloc[idx]['Sentence']\n        encoding = self.tokenizer(\n            sentence,\n            is_split_into_words=True,\n            return_tensors='pt',\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_length,\n            return_special_tokens_mask=True\n        )\n\n        item = {\n            'input_ids': encoding['input_ids'].squeeze(),\n            'attention_mask': encoding['attention_mask'].squeeze(),\n            'word_ids': encoding.word_ids()\n        }\n\n        if not self.is_test:\n            tags = self.data.iloc[idx]['NER Tag']\n            labels = [self.label2id[tag] for tag in tags]\n            aligned_labels = []\n            current_word_id = None\n            for word_id in encoding.word_ids():\n                if word_id is None:\n                    aligned_labels.append(-100)\n                elif word_id != current_word_id:\n                    aligned_labels.append(labels[word_id] if word_id < len(labels) else -100)\n                    current_word_id = word_id\n                else:\n                    aligned_labels.append(-100)\n            item['labels'] = torch.tensor(aligned_labels, dtype=torch.long)\n\n        return item\n\ntest_path = 'data/test.csv'\nif not os.path.exists(test_path):\n    raise FileNotFoundError(f\"Test file {test_path} not found\")\n\ntest_df = pd.read_csv(test_path)\ntest_df['Sentence'] = test_df['Sentence'].apply(ast.literal_eval)\n\nmodel_path = os.path.abspath('model')\nif not os.path.exists(model_path):\n    raise FileNotFoundError(f\"Model directory {model_path} not found\")\n\ntokenizer = AutoTokenizer.from_pretrained(model_path)\nmodel = DebertaCRF.from_pretrained(model_path)\nmodel.eval()\n\nlabel2id = model.config.label2id\nid2label = model.config.id2label\ntest_dataset = NERDataset(test_df, tokenizer, label2id, is_test=True)\n\ntrainer = Trainer(model=model)\npredictions, _, _ = trainer.predict(test_dataset)\n\npred_tags = []\nfor i, pred in enumerate(predictions):\n    sentence = test_df.iloc[i]['Sentence']\n    word_ids = test_dataset[i]['word_ids']\n    pred_ids = pred['predictions']\n    tags = []\n    current_word_id = None\n    token_idx = 0\n    for j, word_id in enumerate(word_ids):\n        if word_id is None:\n            continue\n        if word_id != current_word_id:\n            if token_idx < len(pred_ids):\n                tags.append(id2label[pred_ids[token_idx]])\n                token_idx += 1\n            else:\n                tags.append('O')\n            current_word_id = word_id\n    if len(tags) < len(sentence):\n        tags.extend(['O'] * (len(sentence) - len(tags)))\n    elif len(tags) > len(sentence):\n        tags = tags[:len(sentence)]\n    pred_tags.append(tags)\n\nsubmission_df = pd.DataFrame({\n    'id': test_df['id'],\n    'NER Tag': [str(tags) for tags in pred_tags]\n})\nsubmission_df.to_csv('submission.csv', index=False)\nprint(f\"Submission file saved to submission.csv\")\n\"\"\"\n        with open(os.path.join(submission_dir, 'infer.py'), 'w') as f:\n            f.write(infer_code)\n\n        run_sh = \"\"\"\\\n#!/bin/bash\npip install -r requirements.txt\npython infer.py\n\"\"\"\n        with open(os.path.join(submission_dir, 'run.sh'), 'w') as f:\n            f.write(run_sh)\n\n        os.chmod(os.path.join(submission_dir, 'run.sh'), 0o755)\n        shutil.copy(output_path, os.path.join(submission_dir, 'submission.csv'))\n\n        zip_path = '/kaggle/working/v7_submission.zip'\n        shutil.make_archive(zip_path.replace('.zip', ''), 'zip', submission_dir)\n        print(f\"Zipped submission saved to {zip_path}\")\n\n    except Exception as e:\n        print(f\"Error generating submission: {e}\")\n        raise SystemExit(\"Failed to generate submission.\")\n\ntry:\n    save_trained_model()\n    generate_submission(model, tokenizer, trainer, label2id, id2label)\nexcept Exception as e:\n    print(f\"Error executing save_trained_model or generate_submission: {e}\")\n    raise SystemExit(\"Failed to save model or generate submission.\")","metadata":{"execution":{"iopub.execute_input":"2025-04-29T20:03:56.968266Z","iopub.status.busy":"2025-04-29T20:03:56.968058Z","iopub.status.idle":"2025-04-29T20:04:28.285743Z","shell.execute_reply":"2025-04-29T20:04:28.284769Z"},"papermill":{"duration":31.325096,"end_time":"2025-04-29T20:04:28.287541","exception":false,"start_time":"2025-04-29T20:03:56.962445","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer\nfrom torch.utils.data import Dataset\nimport ast\nimport os\nfrom torchcrf import CRF\n\n# Step 1: Load training data to define label2id and id2label\ndef find_train_csv(input_dir='/kaggle/input'):\n    try:\n        for root, _, files in os.walk(input_dir):\n            if 'train.csv' in files:\n                return os.path.join(root, 'train.csv')\n        return None\n    except Exception as e:\n        print(f\"Error searching for train.csv: {e}\")\n        return None\n\ntrain_path = find_train_csv()\nif not train_path or not os.path.exists(train_path):\n    print(f\"Error: train.csv not found in /kaggle/input\")\n    print(\"Please ensure the 'comp-4211 spring-25-project' dataset is attached in Kaggle's Data tab.\")\n    raise SystemExit(\"Failed to locate train.csv.\")\n\ntry:\n    print(f\"Loading train.csv from {train_path}\")\n    train_df = pd.read_csv(train_path)\n    train_df['Sentence'] = train_df['Sentence'].apply(ast.literal_eval)\n    train_df['NER Tag'] = train_df['NER Tag'].apply(ast.literal_eval)\n    print(f\"Training data loaded successfully. Shape: {train_df.shape}\")\nexcept FileNotFoundError:\n    print(f\"Error: Training file not found at {train_path}\")\n    raise SystemExit(\"Ensure train.csv exists in the specified path.\")\nexcept Exception as e:\n    print(f\"Error loading training data: {e}\")\n    raise SystemExit(\"Failed to load or preprocess training data.\")\n\n# Define labels\ntry:\n    unique_labels = set()\n    for tags in train_df['NER Tag']:\n        unique_labels.update(tags)\n    unique_labels_list = sorted(list(unique_labels))\n    label2id = {v: k for k, v in enumerate(unique_labels_list)}\n    id2label = {k: v for k, v in enumerate(unique_labels_list)}\n    print(f\"Unique labels: {unique_labels_list}\")\n    print(f\"Number of labels: {len(unique_labels_list)}\")\nexcept Exception as e:\n    print(f\"Error defining labels: {e}\")\n    raise SystemExit(\"Failed to process NER tags.\")\n\n# Step 2: Initialize tokenizer\nMODEL_NAME = \"microsoft/deberta-base\"\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True)\n    print(\"Tokenizer initialized successfully.\")\nexcept Exception as e:\n    print(f\"Error initializing tokenizer: {e}\")\n    raise SystemExit(\"Failed to load tokenizer.\")\n\n# Step 3: Define DebertaCRF class\nclass DebertaCRF(AutoModelForTokenClassification):\n    def __init__(self, config):\n        super().__init__(config)\n        self.crf = CRF(num_tags=config.num_labels, batch_first=True)\n\n    def forward(self, input_ids, attention_mask=None, labels=None):\n        outputs = super().forward(input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        if labels is not None:\n            mask = attention_mask.bool()\n            loss = -self.crf(logits, labels, mask=mask, reduction='mean')\n            return {'loss': loss}\n        else:\n            predictions = self.crf.decode(logits, mask=attention_mask.bool())\n            return {'predictions': predictions}\n\n# Step 4: Define NERDataset class\nclass NERDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, label2id, is_test=False):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.label2id = label2id\n        self.is_test = is_test\n        self.max_length = 128\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        sentence = self.data.iloc[idx]['Sentence']\n        encoding = self.tokenizer(\n            sentence,\n            is_split_into_words=True,\n            return_tensors='pt',\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_length,\n            return_special_tokens_mask=True\n        )\n\n        item = {\n            'input_ids': encoding['input_ids'].squeeze(),\n            'attention_mask': encoding['attention_mask'].squeeze(),\n            'word_ids': encoding.word_ids()\n        }\n\n        if not self.is_test:\n            tags = self.data.iloc[idx]['NER Tag']\n            labels = [self.label2id[tag] for tag in tags]\n            aligned_labels = []\n            current_word_id = None\n            for word_id in encoding.word_ids():\n                if word_id is None:\n                    aligned_labels.append(-100)\n                elif word_id != current_word_id:\n                    aligned_labels.append(labels[word_id] if word_id < len(labels) else -100)\n                    current_word_id = word_id\n                else:\n                    aligned_labels.append(-100)\n            item['labels'] = torch.tensor(aligned_labels, dtype=torch.long)\n\n        return item\n\n# Step 5: Function to generate submission using a specific checkpoint\ndef generate_submission_with_checkpoint(checkpoint_path, tokenizer, label2id, id2label, output_path='/kaggle/working/submission.csv'):\n    try:\n        # Load test data\n        test_path = None\n        input_dir = '/kaggle/input'\n        for root, _, files in os.walk(input_dir):\n            if 'test.csv' in files:\n                test_path = os.path.join(root, 'test.csv')\n                break\n        if not test_path or not os.path.exists(test_path):\n            raise FileNotFoundError(f\"Test file not found in {input_dir}.\")\n\n        test_df = pd.read_csv(test_path)\n        test_df['Sentence'] = test_df['Sentence'].apply(ast.literal_eval)\n\n        # Load the model from the specific checkpoint\n        model = DebertaCRF.from_pretrained(checkpoint_path)\n        model.eval()\n\n        # Create test dataset\n        test_dataset = NERDataset(test_df, tokenizer, label2id, is_test=True)\n\n        # Initialize trainer with the loaded model\n        trainer = Trainer(model=model)\n\n        # Generate predictions\n        predictions, _, _ = trainer.predict(test_dataset)\n\n        # Process predictions\n        pred_tags = []\n        for i, pred in enumerate(predictions):\n            sentence = test_df.iloc[i]['Sentence']\n            word_ids = test_dataset[i]['word_ids']\n            pred_ids = pred['predictions'] if isinstance(pred, dict) else np.argmax(pred, axis=-1)\n            tags = []\n            current_word_id = None\n            token_idx = 0\n            for j, word_id in enumerate(word_ids):\n                if word_id is None:\n                    continue\n                if word_id != current_word_id:\n                    if isinstance(pred_ids, list):\n                        if token_idx < len(pred_ids):\n                            tags.append(id2label[pred_ids[token_idx]])\n                            token_idx += 1\n                        else:\n                            tags.append('O')\n                    else:\n                        tags.append(id2label[pred_ids[j]])\n                    current_word_id = word_id\n            if len(tags) < len(sentence):\n                tags.extend(['O'] * (len(sentence) - len(tags)))\n            elif len(tags) > len(sentence):\n                tags = tags[:len(sentence)]\n            pred_tags.append(tags)\n\n        # Create submission DataFrame\n        submission_df = pd.DataFrame({\n            'id': test_df['id'],\n            'NER Tag': [str(tags) for tags in pred_tags]\n        })\n        submission_df.to_csv(output_path, index=False)\n        print(f\"Submission file saved to {output_path}\")\n\n    except Exception as e:\n        print(f\"Error generating submission: {e}\")\n        raise SystemExit(\"Failed to generate submission.\")\n\n# Step 6: Specify the epoch 7 checkpoint path and generate submission\ncheckpoint_path = \"/kaggle/input/derberta/v7_results/checkpoint-7028\"  # Adjust this based on actual checkpoint name for epoch 7\n\n# Verify checkpoint exists\nif not os.path.exists(checkpoint_path):\n    print(os.listdir(\"/kaggle/working/v7_results\"))  # List available checkpoints to help identify the correct one\n    raise FileNotFoundError(f\"Checkpoint for epoch 7 not found at {checkpoint_path}. Please check the checkpoint directory.\")\n\n# Generate submission using epoch 7 checkpoint\ntry:\n    generate_submission_with_checkpoint(checkpoint_path, tokenizer, label2id, id2label)\nexcept Exception as e:\n    print(f\"Error executing generate_submission_with_checkpoint: {e}\")\n    raise SystemExit(\"Failed to generate submission.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-02T15:08:04.132856Z","iopub.execute_input":"2025-05-02T15:08:04.134093Z","iopub.status.idle":"2025-05-02T15:08:04.178199Z","shell.execute_reply.started":"2025-05-02T15:08:04.134047Z","shell.execute_reply":"2025-05-02T15:08:04.177116Z"}},"outputs":[{"name":"stdout","text":"Error: train.csv not found in /kaggle/input\nPlease ensure the 'comp-4211 spring-25-project' dataset is attached in Kaggle's Data tab.\n","output_type":"stream"},{"traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Failed to locate train.csv.\n"],"ename":"SystemExit","evalue":"Failed to locate train.csv.","output_type":"error"}],"execution_count":7}]}